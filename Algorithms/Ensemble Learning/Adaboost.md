## Adaboost

### 1. Boosting 思想

先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注，然后基于调整后的样本分布来训练下一个基学习器。如此重复进行，直至基学习器数目达到事先指定的值 $T$， 最终将这 $T$ 个基学习器进行加权结合。

* **对提升方法来说，有两个问题需要回答：**

  1. 在每一轮如何改变训练数据的权值或概率分布？

  2. 如何将弱分类器组合成一个强分类器？

* **$Boosting$要求基学习器能对特定的数据分布进行学习，一般两种方法（这两种没有显著优劣差别）：**
  1. 重赋权法（$re-weighting$）：适用于可以接受带权样本的基学习器（损失函数对样本加权计算）；
  2. 重采样法（$re-sampling$）：适用于无法接受带权样本的基学习器（抽样时不同样本抽中的概率不同）；

### 2. AdaBoost 算法

* **针对$Boosting$的两个问题，$AdaBoost$的解决思路：**
  1. 提高那些被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类样本的权值。这样一来，那些没有得到正确分类的数据，由于其权值的加大而受到后一轮的弱分类器的更大关注。于是，分类问题被一系列的弱分类器“分而治之”。
  2. AdaBoost采取加权多数表决的方法。具体地，加大分类误差率小的弱分类器的权值，使其在表决中起较大的作用，减小分类误差率大的弱分类器的权值，使其在表决中起较小的作用。
* **具体算法：**

>**输入：** 1.  $T={(x_1,y_1),...,(x_N,y_N)}$, $x_i \in x \subseteq R^n$, $y_i \in y \subseteq \{-1, +1\}$  2. 基学习器
>
>**输出：** 最终分类器$G(x)$
>
>**过程：**
>
>1. 初始化训练数据的权值分布
>
>   $D_1=(w_{11}, w_{12}, w_{13},...,w_{1N}),\ \ w_{1i}=\frac{1}{N},\ \ i=1,2,3,...,N$  
>
>2. $for\ M=1,2,3,...,m\ \ Do$ 
>
>   	$a)$ 使用具有权值分布$D_m$的训练数据集学习，得到基学习器$G_m(x):X->\{-1,+1\}$
>
>   	$b)$ 计算基学习器$G_m$在训练数据集上的分类误差率。注意：权重作为计算每个样本对于总体分类误差		 
>
>   	     率的权重。
>
>   		$$e_m=P(G_m(x_i)\neq y_i)=\sum_{i=1}^{N}w_{mi}I(G_m(x_i) \neq y_i)$$		
>
>   	$c)$ 计算$G_m(x)$的系数，即基学习器组合时的权重，准确率高的基学习器加法模型中权重更大。
>
>   		$$\alpha_m=\frac{1}{2}log\frac{1-e_m}{e_m}$$
>
>   	$d)$ 更新训练数据集的权值分布
>
>   		$$D_{m+1}=(w_{m+1,1}, w_{m+1,2}, w_{m+1,3},...,w_{m+1,N}),\ \ w_{1i}=\frac{1}{N},\ \ i=1,2,...,N$$
>
>   		$$w_{m+1,i}=\frac{w_{m,i}}{Z_m}exp(-\alpha_m y_i G_m(x_i)), \ \ i=1,2,...,N$$
>
>   		$$Z_m=\sum_{i=1}^m{w_{m,i}exp(-\alpha_m y_i G_m(x_i))}$$  , 规范化因子使$D_{m+1}$成为一个概率分布
>
>3. 构建基本分类器的线性组合
>
>   		$$f(x)=\sum_{m=1}^M{\alpha_m G_m(x)}$$ 
>
>   		$$G(x)=sign(f(x))=sign(\sum_{m=1}^M{\alpha_m G_m(x)})$$

* **对算法的几点说明：**

  * $2.b：$ $Gm(x)$在加权的训练数据集上的分类误差率是$Gm(x)$误分类样本的权值之和，由此可以看出数据权值分布$Dm$与基本分类器$Gm(x)$的分类误差率的关系。误分类样本权值和越大，分类误差率越大。

  * $2.c：$ 由系数计算公式可知，当$e_m \leq \frac{1}{2}$ 时，$\alpha_m \geq 0$ ，并且$a_m$随着$e_m​$的减小而增大，所以分类误差率越小的基本分类器在最终分类器中的作用越大。






### 3. AdaBoost 训练误差分析



### 4. AdaBoost 推导

#### 4.1 加法模型与前向分步算法



#### 4.2 推导 AdaBoost



### 5. 实例



