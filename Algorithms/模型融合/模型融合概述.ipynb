{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型融合概述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文转自：一份完备的集成学习手册[https://mp.weixin.qq.com/s/Pkc8KyDZ53ZGO5lNLVjoBg]\n",
    "\n",
    "根据该文章稍作修改，文档中具体算法的实现参见本项目其他文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目录\n",
    "#### 1. 基本的融合技术\n",
    "\n",
    "    1.1 最大化\n",
    "\n",
    "    1.2 平均化\n",
    "\n",
    "    1.3 加权平均\n",
    "\n",
    "#### 2. 高级融合技术\n",
    "\n",
    "    2.1 Stacking\n",
    "\n",
    "    2.2 Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  基本的集成技术（略）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 高级集成技术"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking 是使用多个模型（例如决策树、KNN、SVM）来构建新的模型的集成技术。该模型在测试集上进行预测。下面是一个简单的 Stacking 集成的详细步骤解释。\n",
    "\n",
    "1）将训练集划分为 10 个子集。\n",
    "\n",
    "2）在其中 9 个子集上训练一个基本模型（例如决策树模型），在第 10 个子集上进行测试。遍历每个子集，重复进行 10 次。得到的 DT 长度与 Train set 相同。\n",
    "![1](https://mmbiz.qpic.cn/mmbiz_png/hflWRBRSEZ6Ccb2zNuL3r3TvQRPIFykKfHaYfuvsTku91N6xFzA7iaMF8AjA0y9GTXPZicenOYycBubETglibhZkA/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n",
    "3）在整个训练集上使用该模型（决策树）进行建模。\n",
    "\n",
    "4）使用建模的模型在测试集上进行测试。\n",
    "![2](https://mmbiz.qpic.cn/mmbiz_png/hflWRBRSEZ6Ccb2zNuL3r3TvQRPIFykKJ0nc1yYs53yEcj0eZoVKfA65XFPoCkyXZdxVTtoLaElLy5JiaGGqfFw/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n",
    "\n",
    "5）使用另一种算法（例如 knn），重复步骤 2～4，作用在 Train set 和 Test set 上，得到另一组值。\n",
    "![3](https://mmbiz.qpic.cn/mmbiz_png/hflWRBRSEZ6Ccb2zNuL3r3TvQRPIFykKgOkpy85tORSHowuIn0hQ88SniclGEG7y4N1C56S9XcAVvhjsqx9mVQA/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n",
    "\n",
    "6）使用得到的 DT 和 knn 组合作为新的特征 TRAIN PREDICTION SET，训练新的模型（例如逻辑回归）。\n",
    "![4](https://mmbiz.qpic.cn/mmbiz_png/hflWRBRSEZ6Ccb2zNuL3r3TvQRPIFykKY3jsZa3SSys3K3LiaxibG1e38ap4B1cG8FswicPACHrfaRuJibveu02w4g/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n",
    "\n",
    "7）使用训练好的模型对 TEST PREDICTION SET 进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例\n",
    "# 为了将问题简单化，所创建的 Stacking 模型只有两层。第一层是建立决策树和 knn 模型，两个基学习器，第二层是建立逻辑回归模型。实际应用中可以使用多个层次的复杂结构。\n",
    "# 首先，我们需要定义一个函数对 n 折训练集和测试集进行预测，该函数返回每个模型对训练集和测试集的预测结果。\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 使用Kaggle Titanic数据集\n",
    "train = pd.read_csv('../../Data/train_fixed.csv')\n",
    "test = pd.read_csv('../../Data/test_fixed.csv')\n",
    "train_X = train.drop(['Survived'], axis=1)\n",
    "train_y = train['Survived']\n",
    "\n",
    "# for train, test in folds.split(train_X, train_y):\n",
    "#     print('train: ', train)\n",
    "#     print('test: ', test)\n",
    "#     print('----------------------------------')\n",
    "\n",
    "def Stacking(model, train_X, train_y, test_X, n_fold, model_name):\n",
    "    folds=StratifiedKFold(n_splits=n_fold, random_state=1)\n",
    "    test_pred_nfolds = pd.DataFrame(np.empty((test_X.shape[0], n_fold)), dtype=float, columns=['test_pred_fold' + str(i) for i in np.arange(0,n_fold)])\n",
    "    train_pred = pd.DataFrame(np.empty((train_X.shape[0], 1)), dtype=float, columns=[model_name])\n",
    "    fold = 0\n",
    "    for train_index, val_index in folds.split(train_X, train_y.values):\n",
    "        x_train, x_val = train_X.iloc[train_index], train_X.iloc[val_index]\n",
    "        y_train, y_val = train_y.iloc[train_index], train_y.iloc[val_index]\n",
    "\n",
    "        # 训练模型\n",
    "        model.fit(X=x_train, y=y_train)\n",
    "\n",
    "        # 判断该折验证集模型效果\n",
    "        # y_val_hat = model.predict(x_val) & y_val\n",
    "\n",
    "        # 合并各折预测值，得到训练集整体预测值；每折都对测试集进行一次预测，最后取平均作为测试集最终取值 \n",
    "        train_pred[model_name].iloc[val_index] = model.predict(x_val)\n",
    "        test_pred_nfolds.iloc[:, fold] = model.predict(test_X)\n",
    "        \n",
    "        fold += 1\n",
    "    \n",
    "    test_pred = test_pred_nfolds.mean(axis=1)\n",
    "\n",
    "    return train_pred, test_pred\n",
    "\n",
    "# 构建两个基本模型：决策树和 knn\n",
    "model1 = tree.DecisionTreeClassifier(random_state=1)\n",
    "train_pred1, test_pred1 =Stacking(model=model1, train_X=train_X, train_y=train_y, test_X=test, n_fold=10, model_name='tree')\n",
    "\n",
    "model2 = KNeighborsClassifier()\n",
    "train_pred2, test_pred2 =Stacking(model=model2, train_X=train_X, train_y=train_y, test_X=test, n_fold=10, model_name='knn')\n",
    "\n",
    "# 使用逻辑回归，进行训练和预测。\n",
    "df = pd.concat([train_pred1, train_pred2], axis=1)\n",
    "df_test = pd.concat([test_pred1, test_pred2], axis=1)\n",
    "df_test.columns = ['tree', 'knn']\n",
    "\n",
    "model = LogisticRegression(random_state=1)\n",
    "model.fit(df, train_y)\n",
    "pred_y = model.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blending 与 Stacking 类似，但是仅从训练集上划分一部分作为 holdout（验证集），没有使用 k 折验证。Holdout 集结果作为下一层的训练数据。下面是 Blending 的详细步骤解释。\n",
    "\n",
    "    1. 将所有的训练数据划分为训练集和验证集。\n",
    "![blending1](https://mmbiz.qpic.cn/mmbiz_png/hflWRBRSEZ6Ccb2zNuL3r3TvQRPIFykKZAp6tMLxbwkcCAf31qAYzDGGRq6RrErF81zkDB8CQqXBCAQcaxjByw/640?tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)\n",
    "    \n",
    "    2. 在训练集上训练模型。\n",
    "\n",
    "    3. 在验证集和整体测试集上进行模型测试。\n",
    "\n",
    "    4. 验证集和测试结果作为元特征，进行第二层的模型训练。\n",
    "\n",
    "    5. 使用该模型在整体测试集的元特征上进行模型验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 使用Kaggle Titanic数据集\n",
    "train_dt = pd.read_csv('../../Data/train_fixed.csv')\n",
    "test_dt = pd.read_csv('../../Data/test_fixed.csv')\n",
    "\n",
    "train_index = pd.Series(np.arange(train.shape[0])).sample(n=int(train.shape[0]/4*3))\n",
    "val_index = pd.Series([x for x in np.arange(train.shape[0]) if x not in train_index])\n",
    "\n",
    "train = train_dt.iloc[train_index]\n",
    "val = train_dt.iloc[val_index]\n",
    "test_X = test_dt\n",
    "\n",
    "train_X = train.drop(['Survived'], axis=1)\n",
    "train_y = train['Survived']\n",
    "val_X = val.drop(['Survived'], axis=1)\n",
    "val_y = val['Survived']\n",
    "\n",
    "# 首先，我们在训练集上训练两个模型：决策树和 knn，以便在验证集上作出预测。\n",
    "model1 = tree.DecisionTreeClassifier()\n",
    "model1.fit(train_X, train_y)\n",
    "val_pred1 = model1.predict(val_X)\n",
    "test_pred1 = model1.predict(test_X)\n",
    "val_pred1 = pd.DataFrame(val_pred1, index=val_X.index, columns=['tree'])\n",
    "test_pred1 = pd.DataFrame(test_pred1, columns=['tree'])\n",
    "\n",
    "model2 = KNeighborsClassifier()\n",
    "model2.fit(train_X, train_y)\n",
    "val_pred2 = model2.predict(val_X)\n",
    "test_pred2 = model2.predict(test_X)\n",
    "val_pred2 = pd.DataFrame(val_pred2, index=val_X.index, columns=['knn'])\n",
    "test_pred2 = pd.DataFrame(test_pred2, columns=['knn'])\n",
    "\n",
    "# 然后，结合验证集的元特征，训练逻辑回归模型，在测试集上进行验证。\n",
    "df_val_layer2 = pd.concat([val_X, val_pred1, val_pred2],axis=1)\n",
    "df_test_layer2 = pd.concat([test_X, test_pred1, test_pred2],axis=1)\n",
    "\n",
    "model_layer2 = LogisticRegression()\n",
    "model_layer2.fit(df_val_layer2, val_y)\n",
    "test_y_pred = model_layer2.predict(df_test_layer2)\n",
    "# roc_auc_score(test_y, test_y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
